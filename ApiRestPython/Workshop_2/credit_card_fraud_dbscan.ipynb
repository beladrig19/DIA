{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"card_credit_fraud.csv\")\n",
    "\n",
    "n = len(df) // 4\n",
    "df = df.iloc[:n]\n",
    "\n",
    "n = len(df) // 2\n",
    "df = df.iloc[:n]\n",
    "\n",
    "\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', 'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "\n",
    "df['nameOrig'] = df['nameOrig'].str.replace('C', '0', regex=False)\n",
    "df['nameOrig'] = df['nameOrig'].str.replace('M', '1', regex=False)\n",
    "\n",
    "df['nameDest'] = df['nameDest'].str.replace('C', '0', regex=False)\n",
    "df['nameDest'] = df['nameDest'].str.replace('M', '1', regex=False)\n",
    "\n",
    "df['nameOrig'] = df['nameOrig'].astype('category').cat.codes\n",
    "df['nameDest'] = df['nameDest'].astype('category').cat.codes\n",
    "\n",
    "Y = df['isFraud']\n",
    "X = df.drop(['isFraud'], axis=1)\n",
    "\n",
    "X.loc[X.type == 'TRANSFER', 'type'] = 0\n",
    "X.loc[X.type == 'CASH_OUT', 'type'] = 1\n",
    "X.loc[X.type == 'PAYMENT', 'type'] = 2\n",
    "X.loc[X.type == 'CASH_IN', 'type'] = 3\n",
    "X.loc[X.type == 'DEBIT', 'type'] = 4\n",
    "\n",
    "X.type = X.type.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clustering', DBSCAN())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'clustering__eps': [0.5, 1],\n",
    "    'clustering__min_samples': [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data has more than 2 dimensions, apply PCA to reduce it to 2 dimensions for visualization.\n",
    "pca = PCA(n_components=2)\n",
    "trainX_pca = pca.fit_transform(trainX)\n",
    "testX_pca = pca.transform(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "\n",
    "# Iterate over each set of parameters in the parameter grid\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Set the parameters for the pipeline\n",
    "    pipeline.set_params(**params)\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipeline.fit(trainX_pca)\n",
    "\n",
    "    # Access the cluster labels for the training data\n",
    "    y_pred = pipeline.named_steps['clustering'].labels_\n",
    "\n",
    "    # Check if there are at least 2 clusters (excluding noise)\n",
    "    unique_labels = set(y_pred)\n",
    "    if len(unique_labels) > 1 and -1 in unique_labels:\n",
    "        if len(unique_labels) == 2:  # Only one cluster and noise\n",
    "            silhouette_scores.append(float('nan'))  # or some indicator value for undefined score\n",
    "        else:\n",
    "            # Calculate the silhouette score for the training data\n",
    "            silhouette_score_train = silhouette_score(trainX_pca, y_pred)\n",
    "            # Append the silhouette score to the list\n",
    "            silhouette_scores.append(silhouette_score_train)\n",
    "    elif len(unique_labels) > 2:  # More than 2 clusters, no noise check needed\n",
    "        # Calculate the silhouette score for the training data\n",
    "        silhouette_score_train = silhouette_score(trainX_pca, y_pred)\n",
    "        # Append the silhouette score to the list\n",
    "        silhouette_scores.append(silhouette_score_train)\n",
    "    else:\n",
    "        # If there's only one cluster or all points are noise, skip or handle differently\n",
    "        silhouette_scores.append(float('nan')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the highest silhouette score\n",
    "best_index = np.argmax(silhouette_scores)\n",
    "\n",
    "parameter_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_parameters_combination = parameter_combinations[best_index]\n",
    "\n",
    "# Get the best silhouette score\n",
    "best_score = silhouette_scores[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'clustering__eps': 0.5, 'clustering__min_samples': 5}\n",
      "Best Silhouette Score:  nan\n"
     ]
    }
   ],
   "source": [
    "# Print the best set of parameters and the best silhouette score\n",
    "print(\"Best Parameters: \", best_parameters_combination)\n",
    "print(\"Best Silhouette Score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_params(**best_parameters_combination).fit(trainX_pca)\n",
    "\n",
    "# Predict the cluster labels for the test data\n",
    "y_pred_test = pipeline.named_steps['clustering'].labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the silhouette score for the test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m silhouette_score_train \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39msilhouette_score(trainX_pca, y_pred_test)\n\u001b[0;32m      4\u001b[0m adjusted_rand_score_value \u001b[38;5;241m=\u001b[39m adjusted_rand_score(testY, y_pred_test)\n\u001b[0;32m      5\u001b[0m davies_bouldin_score_value \u001b[38;5;241m=\u001b[39m davies_bouldin_score(testX_pca, y_pred_test)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:117\u001b[0m, in \u001b[0;36msilhouette_score\u001b[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:231\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[1;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[0;32m    229\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[0;32m    230\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[1;32m--> 231\u001b[0m check_number_of_labels(\u001b[38;5;28mlen\u001b[39m(le\u001b[38;5;241m.\u001b[39mclasses_), n_samples)\n\u001b[0;32m    233\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m    234\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m    235\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[0;32m    236\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:33\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[1;34m(n_labels, n_samples)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[0;32m     36\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "# Calculate the silhouette score for the test data\n",
    "silhouette_score_train = sklearn.metrics.silhouette_score(trainX_pca, y_pred_test)\n",
    "\n",
    "adjusted_rand_score_value = adjusted_rand_score(testY, y_pred_test)\n",
    "davies_bouldin_score_value = davies_bouldin_score(testX_pca, y_pred_test)\n",
    "calinski_harabasz_score_value = calinski_harabasz_score(testX_pca, y_pred_test)\n",
    "\n",
    "# Print the silhouette score for the test data\n",
    "print(\"Silhouette Score for Test Data: \", silhouette_score_train)\n",
    "print(\"Adjusted Rand Score for Test Data: \", adjusted_rand_score_value)\n",
    "print(\"Davies Bouldin Score for Test Data: \", davies_bouldin_score_value)\n",
    "print(\"Calinski Harabasz Score for Test Data: \", calinski_harabasz_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training data\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(trainX_pca[:, 0], trainX_pca[:, 1], c=pipeline.predict(trainX_pca), cmap='viridis', marker='o', edgecolor='k', s=50, alpha=0.7, label='Training Data')\n",
    "plt.title('Clusters of Training Data')\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "\n",
    "# Plot test data\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(testX_pca[:, 0], testX_pca[:, 1], c=y_pred_test, cmap='viridis', marker='o', edgecolor='k', s=50, alpha=0.7, label='Test Data')\n",
    "plt.title('Clusters of Test Data')\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
